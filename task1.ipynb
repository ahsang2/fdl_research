{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  machine learning\n",
      "1                 genetic algorithm\n",
      "2                    classification\n",
      "3                     deep learning\n",
      "4                       data mining\n",
      "                   ...             \n",
      "9995    empirical risk minimization\n",
      "9996                  global motion\n",
      "9997                 retinal images\n",
      "9998       unequal error protection\n",
      "9999             dark channel prior\n",
      "Name: 0, Length: 9999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#load needed rows and columns into dataframe\n",
    "df = pd.read_csv('concepts.csv', header=None, nrows=10000)\n",
    "df.dropna(axis='columns', inplace=True, thresh=9999)\n",
    "\n",
    "#preprocessing, delete extra row\n",
    "#from itertools import compress\n",
    "#tf2 = df[df.columns[0]].isna()\n",
    "#list(compress(range(len(tf2)), tf2))\n",
    "#print(tf2[3484])\n",
    "#print(df.iloc[3484])\n",
    "df.dropna(axis='rows', inplace=True)\n",
    "print(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse json, code is from https://www.kaggle.com/srishti280992/prep-data-for-coauthorship-analysis\n",
    "import json\n",
    "\n",
    "articles = []\n",
    "category = 'nucl-ex'\n",
    "with open(\"papers.json\", \"r\") as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        if category in d['categories'].split(' '):\n",
    "            articles.append(d)\n",
    "\n",
    "articles_df = pd.DataFrame().from_records(articles)\n",
    "articles_df.head()\n",
    "\n",
    "clean_abstract = []\n",
    "i = 0\n",
    "for i,a in articles_df.iterrows():\n",
    "    # Clean abstract\n",
    "    i += 1\n",
    "    if i == 10000:\n",
    "        break\n",
    "    try:\n",
    "        clean_abstract.append(LatexNodes2Text().latex_to_text(a['abstract']).replace('\\n', ' ').strip()) \n",
    "    except:\n",
    "        clean_abstract.append(a['abstract'].replace('\\n', ' ').strip())\n",
    "#clean_abstract[0]\n",
    "#articles_df['abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ahsangilani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load abstracts into whoosh database\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh import index\n",
    "\n",
    "schema = Schema(content=TEXT(stored=True))\n",
    "ix = index.create_in(\".\", schema)\n",
    "writer = ix.writer()\n",
    "for i in range(len(clean_abstract)):\n",
    "    sents = nltk.tokenize.sent_tokenize(clean_abstract[i])\n",
    "    for j in range(len(sents)):\n",
    "        writer.add_document(content = sents[j])   \n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    " \n",
    "def search(term):\n",
    "    ret = np.array([])\n",
    "    \n",
    "    with ix.searcher() as searcher:\n",
    "        query = QueryParser(\"content\", ix.schema).parse(term)\n",
    "        results = searcher.search(query, terms=True, limit = 100)\n",
    "        for r in results:\n",
    "            ret = np.append(ret, r['content'])\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['This experiment is a continuation of the currently running SeaQuest experiment.',\n",
       "       'The NA60 experiment is a fixed-target experiment at the CERN SPS.',\n",
       "       'ALICE (A Large Ion Collider Experiment) is the LHC experiment dedicated to the study of the QGP.',\n",
       "       'ALICE (A Large Ion Collider Experiment) is the dedicated heavy-ion experiment at the LHC.',\n",
       "       'The design of the experiment is presented.',\n",
       "       'The detail of the experiment is described.',\n",
       "       'Data of an early experiment and the recent Crystal Ball experiment at BNL are included in the analysis with the c.m.',\n",
       "       \"The results of the experiment's commissioning run are reported here, constituting approximately 4% of the data collected in the experiment.\",\n",
       "       'The Main Injector Particle Production (MIPP) experiment is a fixed target hadron production experiment at Fermilab.',\n",
       "       'ALICE (A Large Ion Collider Experiment) is the dedicated heavy ion experiment at the Large Hadron Collider at CERN.',\n",
       "       'The experiment is of \"formation\" type, i.e.',\n",
       "       'An overview and status of the experiment are given.',\n",
       "       'This experiment will be performed in liquid helium at ?',\n",
       "       'The analysis of a planned experiment is discussed.',\n",
       "       'A detailed description of the experiment is presented.',\n",
       "       'An overview of the experiment and its results using the commissioning dataset, constituting approximately 4% of the data collected in the experiment, are reported here.',\n",
       "       'NEMO 3 is a double beta decay experiment.',\n",
       "       'The first year results of this experiment are discussed.',\n",
       "       'No strangelets were found in the experiment.',\n",
       "       'The results are measured in the STAR experiment at RHIC.',\n",
       "       'We report the final result of the CUORICINO experiment.',\n",
       "       'An overview and current status of the experiment will be presented.',\n",
       "       'The results are measured in the STAR experiment at RHIC.',\n",
       "       'The experiment is described and numerical simulations are presented.',\n",
       "       'Predictions are made for an upcoming JLab experiment.',\n",
       "       'Predictions are made for an upcoming JLab experiment.',\n",
       "       'Example of application in Z=115 experiment is presented.',\n",
       "       'The proposed experiment could serve as a commissioning experiment of the new SHMS together with the HMS in Hall C. A total beam time of 21 days is requested.',\n",
       "       'None of them have been found to agree with experiment.',\n",
       "       'Preliminary results from an experiment aiming at Dy-170.',\n",
       "       '2) $\\\\beta$-decay experiment a Louvain la Neuve.',\n",
       "       'This study was performed on the bolometers of the CUORE experiment.',\n",
       "       'ALICE is the dedicated heavy-ion experiment at the LHC.',\n",
       "       'Small structures observed in a previous experiment are not confirmed.',\n",
       "       'Its inclusion much improves agreement with experiment.',\n",
       "       'ALICE is the dedicated heavy-ion experiment at the LHC.',\n",
       "       'The data were taken with the HADES experiment at GSI.',\n",
       "       'In this review, an overview of the experiment and the final results are presented.',\n",
       "       'ALICE is the dedicated heavy-ion experiment at the LHC.',\n",
       "       'ALICE is the dedicated heavy-ion experiment at the LHC.',\n",
       "       'However the experiment looks feasible at either location.',\n",
       "       'obtained with the published background data from the XENON100 experiment.',\n",
       "       'The experiment can be performed by using the existing LHCf detector.',\n",
       "       'It is crucial for the experiment to understand the performance of the HPGe crystals.',\n",
       "       'MeV was measured, in agreement with an earlier experiment.',\n",
       "       'In this paper we present results from the RHIC PHENIX experiment.',\n",
       "       'We propose an experiment for an accurate measurement of the proton radius.',\n",
       "       'B 483 (2000) 15] because of the strong disagreement by 5.6 standard deviations between the results of this experiment and our experiment [A. Serebrov et al., Phys.',\n",
       "       'SuperNEMO is a next-generation double beta decay experiment based on the successful tracking plus calorimetry design approach of the recently stopped NEMO3 experiment.',\n",
       "       'The PHENIX experiment has experiment has ability to study the CNM effects by measuring heavy quark production in $d$$+$Au collisions at variety of kinematic ranges.',\n",
       "       'NEXT (Neutrino Experiment with a Xenon TPC) is a neutrinoless double-beta (\\\\beta \\\\beta 0\\\\nu) decay experiment that will operate at the Canfranc Underground Laboratory (LSC).',\n",
       "       'Measurements of $B_n$, for the production of a $\\\\Delta(1232)$ resonance from a proton target, will soon become available from the Qweak experiment at Jefferson Lab and the A4 experiment at Mainz.',\n",
       "       'This formulation is intended for application in the OLYMPUS experiment and the upcoming DarkLight experiment, but is applicable to a broad range of experiments at energies where QED is a sufficient description.',\n",
       "       'In the micrometer range, we present sensitivity of the future GRANIT experiment.',\n",
       "       'A remarkable agreement between model and experiment was achieved.',\n",
       "       'This experiment will be complementary to Q^p_weak in terms of sensitivity to New Physics.',\n",
       "       'The upgraded experiment took data twice, in 1999 and in 2000.',\n",
       "       'The present study reports on experiment performed to address this phenomenon.',\n",
       "       'The first physics experiment on these hypernuclei is planned for 2009.',\n",
       "       'The data have been recorded by the CERES experiment at the CERN-SPS.',\n",
       "       'The calculated ratios are in good agreement with those extracted from the experiment.',\n",
       "       'The performance of MPPCs are found to satisfy the requirement of T2K experiment.',\n",
       "       'We further discuss the requests for an experiment aiming to obtain this result.',\n",
       "       'The MuSun experiment will deduce Lambda_d to better than 1.5%.',\n",
       "       'Flux is an important source of uncertainties for a reactor neutrino experiment.',\n",
       "       'The experiment configuration, achievements to date, status and plans are discussed.',\n",
       "       'We review some important results from the PHENIX experiment at RHIC.',\n",
       "       'The implications of these results for the NEXT experiment are also discussed.',\n",
       "       'Also, the upcoming SIDDHARTA-2 kaonic deuterium experiment is introduced.',\n",
       "       'These studies are relevant for the upcoming PANDA experiment at FAIR.',\n",
       "       'The ALICE experiment features multiple particle identification systems.',\n",
       "       'This presents a challenge to both theory and experiment for improved understanding.',\n",
       "       'As in the case of the first approach, a dedicated ancillary experiment is mandatory.',\n",
       "       'This is understandable because it follows from the way the experiment is performed-e.g.',\n",
       "       'The present status of theory and experiment for these quantities are presented.',\n",
       "       'He proposes a space-based experiment to detect this effect.',\n",
       "       'A new approach to the free fall experiment with UCN is proposed.',\n",
       "       'In this paper we will discuss how to improve the accuracy of the direct experiment.',\n",
       "       'Considering the PANDA experiment to be an ideal platform to explore the production of the charmonium and charmonim-like states, we suggest the forthcoming PANDA experiment to pay attention to the production of $Z^\\\\pm(4430)$.',\n",
       "       'Counting rates show that the experiment looks feasible with the real photon beam characteristics expected at JLab@12 GeV, and with the quasi real photon beam in the COMPASS experiment.',\n",
       "       'We report on recent heavy flavor measurements from the STAR experiment at RHIC.',\n",
       "       'The NA60 experiment studies muon pair production at the CERN SPS.',\n",
       "       'The Geant4 based simulation package MaGe is used to simulate the experiment.',\n",
       "       'The data are in good agreement with results obtained in the former DLS experiment.',\n",
       "       'Finally the perspectives for the multiplicity measurement in the ALICE experiment at the LHC are discussed.',\n",
       "       'We study the production of $Z^\\\\pm(4430)$ at a nucleon-antinucleon scattering experiment.',\n",
       "       'The Heavy Flavor Tracker (HFT) is a proposed upgrade of the STAR experiment.',\n",
       "       'The ALICE experiment at LHC is mainly dedicated to heavy-ion physics.',\n",
       "       'The SNO+ experiment is the follow-up to the Sudbury Neutrino Observatory (SNO).',\n",
       "       'The experiment uses the cooling electron beam at COSY as an electron target.',\n",
       "       'The experiment to observe the modulation is proposed for ions stored in a Penning trap.',\n",
       "       'We report on the development of a GEM-based TPC prototype for the PANDA experiment.',\n",
       "       'The experiment was performed at LNS-Catania using the CHIMERA multidetector.',\n",
       "       'This experiment reinforces our first observation of Rg in a terrestrial material.',\n",
       "       'First addressed in this article, both in theory and experiment, is the problem of baryogenesis ...',\n",
       "       'Advantages of performing the experiment at the Daya Bay far site are described.',\n",
       "       'I will also discuss the possibilities for scaling up to a neutrino-mass experiment.',\n",
       "       'In this paper selected results obtained by the ALICE experiment at the LHC will be presented.',\n",
       "       'The experiment is based on comparision of spectra measured with natural and enriched xenon.',\n",
       "       '46 (1995) 455-456] is fully discarded by the present experiment.'],\n",
       "      dtype='<U224')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = \"experiment\"\n",
    "matches = search(term)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = dict((k,0) for k in df[0])\n",
    "outputs = dict((k,\"\") for k in df[0])\n",
    "\n",
    "def output(concepts, outputs):\n",
    "    o = list(reversed(sorted(concepts.items(), key=lambda item: item[1])))\n",
    "    #print(o)\n",
    "    print(outputs[o[0][0]])\n",
    "    print(outputs[o[1][0]])\n",
    "    print(outputs[o[2][0]])\n",
    "\n",
    "def rank(term, matches, scores, outputs):\n",
    "    for sent in matches:\n",
    "        for k in scores:\n",
    "            words = sent.split()\n",
    "            if k in words:\n",
    "                scores[k] += 1\n",
    "                i1 = words.index(k)\n",
    "                i2 = [idx for idx, s in enumerate(words) if term in s][0]\n",
    "                scores[k] += len(words) - abs(i1 - i2)\n",
    "                if outputs[k] == \"\":\n",
    "                    outputs[k] = sent\n",
    "                    \n",
    "    output(scores, outputs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This experiment is a continuation of the currently running SeaQuest experiment.\n",
      "The Main Injector Particle Production (MIPP) experiment is a fixed target hadron production experiment at Fermilab.\n",
      "The results of the experiment's commissioning run are reported here, constituting approximately 4% of the data collected in the experiment.\n"
     ]
    }
   ],
   "source": [
    "rank(term, matches, concepts, outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
